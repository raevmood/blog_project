{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319d5847",
   "metadata": {},
   "source": [
    "## Gemini API call attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfa27372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, let's break down **Cosines** in a few layers, starting simple and building up.\n",
      "\n",
      "At its heart, cosine is a way to describe how angles relate to distances or positions.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. The Basics: Right Triangles (SOH CAH TOA)\n",
      "\n",
      "This is usually where people first meet cosine.\n",
      "\n",
      "Imagine you have a **right-angled triangle** (a triangle with one 90-degree corner). Let's pick one of the *other* two angles (not the 90-degree one) and call it **θ** (theta).\n",
      "\n",
      "*   **Hypotenuse:** The longest side, opposite the right angle.\n",
      "*   **Opposite:** The side directly across from angle θ.\n",
      "*   **Adjacent:** The side next to angle θ that is *not* the hypotenuse.\n",
      "\n",
      "**Cosine (cos)** is a **ratio** of two of these sides:\n",
      "\n",
      "***\n",
      "**C**os **A**djacent **H**ypotenuse\n",
      "\n",
      "**Cos(θ) = Adjacent / Hypotenuse**\n",
      "***\n",
      "\n",
      "**What does this mean?**\n",
      "If you know an angle in a right triangle and the length of the hypotenuse, cosine helps you find the length of the adjacent side. Or, if you know the adjacent side and hypotenuse, it helps you find the angle.\n",
      "\n",
      "**Example:**\n",
      "Imagine a ladder leaning against a wall.\n",
      "*   The ladder is the **hypotenuse**.\n",
      "*   The ground is the **adjacent** side (relative to the angle the ladder makes with the ground).\n",
      "*   The wall is the **opposite** side.\n",
      "\n",
      "If the ladder is 10 feet long and it makes a 60-degree angle with the ground:\n",
      "`cos(60°) = Adjacent / 10 feet`\n",
      "Since `cos(60°) = 0.5` (a common value to remember or look up):\n",
      "`0.5 = Adjacent / 10`\n",
      "`Adjacent = 0.5 * 10 = 5 feet`\n",
      "So, the base of the ladder is 5 feet away from the wall.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Beyond Right Triangles: The Unit Circle\n",
      "\n",
      "This is where cosine becomes more powerful and general.\n",
      "\n",
      "Imagine a circle with a radius of **1** unit centered at the origin (0,0) of a coordinate plane. This is called the **unit circle**.\n",
      "\n",
      "*   Start at the point (1,0) on the circle (this is 0 degrees).\n",
      "*   Now, draw a line from the center (0,0) out to any point on the circle. This line makes an angle **θ** with the positive x-axis.\n",
      "*   The **x-coordinate** of the point where your line touches the circle is the **cosine of the angle θ**.\n",
      "*   The **y-coordinate** of that point is the **sine of the angle θ**.\n",
      "\n",
      "**Why is this important?**\n",
      "1.  **Any Angle:** It allows us to define cosine for *any* angle, not just angles inside a right triangle (which must be between 0 and 90 degrees). You can have angles greater than 90 degrees, negative angles, angles over 360 degrees.\n",
      "2.  **Positive/Negative Values:** The x-coordinate can be positive or negative depending on what quadrant the point is in.\n",
      "    *   In Quadrant I (0-90°), x is positive, so cos(θ) is positive.\n",
      "    *   In Quadrant II (90-180°), x is negative, so cos(θ) is negative.\n",
      "    *   In Quadrant III (180-270°), x is negative, so cos(θ) is negative.\n",
      "    *   In Quadrant IV (270-360°), x is positive, so cos(θ) is positive.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. The Cosine Wave (Graph)\n",
      "\n",
      "If you plot the value of `cos(θ)` for all possible angles `θ`, you get a smooth, repeating wave shape.\n",
      "\n",
      "*   It starts at its maximum value (1) when `θ = 0°`.\n",
      "*   It goes down to 0 when `θ = 90°`.\n",
      "*   It goes down to its minimum value (-1) when `θ = 180°`.\n",
      "*   It goes back to 0 when `θ = 270°`.\n",
      "*   It returns to 1 when `θ = 360°` (and the cycle repeats).\n",
      "\n",
      "This wave is fundamental to describing anything that oscillates or vibrates smoothly, like sound waves, light waves, alternating current (AC) electricity, springs, pendulums, etc.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. The Law of Cosines\n",
      "\n",
      "This is a powerful formula that extends the Pythagorean theorem and allows you to solve *any* triangle (not just right-angled ones) if you have certain information.\n",
      "\n",
      "If you have a triangle with sides `a`, `b`, `c` and angles `A`, `B`, `C` opposite those sides:\n",
      "\n",
      "**`c² = a² + b² - 2ab * cos(C)`**\n",
      "\n",
      "*   **How it works:** If you know two sides (`a`, `b`) and the angle *between* them (`C`), you can find the third side (`c`).\n",
      "*   **Connection to Pythagoras:** If `C` is a right angle (90°), then `cos(C) = cos(90°) = 0`. The formula then simplifies to `c² = a² + b²`, which is the Pythagorean theorem!\n",
      "\n",
      "---\n",
      "\n",
      "### 5. Intuition: The \"Shadow\" or \"Component\"\n",
      "\n",
      "Think of cosine as giving you the \"horizontal component\" or \"how much something aligns with a particular direction.\"\n",
      "\n",
      "**Analogy:**\n",
      "Imagine you have a flashlight (light source) directly above the X-axis. You hold a stick.\n",
      "*   If you hold the stick **horizontally** (0° angle with the ground), its shadow on the ground is the full length of the stick. `cos(0°) = 1`.\n",
      "*   If you tilt the stick to a **45° angle**, its shadow on the ground will be shorter. `cos(45°) ≈ 0.707`. The shadow is about 70.7% of the stick's length.\n",
      "*   If you hold the stick **vertically** (90° angle with the ground), its shadow on the ground is just a point (0 length). `cos(90°) = 0`.\n",
      "\n",
      "Cosine tells you \"how much of the stick's length is projected onto the horizontal line.\"\n",
      "\n",
      "---\n",
      "\n",
      "### In Summary:\n",
      "\n",
      "*   **Right Triangles:** `cos(angle) = Adjacent / Hypotenuse` (ratio of sides).\n",
      "*   **Unit Circle:** `cos(angle) = x-coordinate` (horizontal position).\n",
      "*   **Wave:** Describes cycles and oscillations.\n",
      "*   **Law of Cosines:** Solves any triangle.\n",
      "*   **Intuition:** How much something \"points\" or \"projects\" in a horizontal or reference direction.\n",
      "\n",
      "Cosines are incredibly useful in physics (breaking forces into components), engineering (designing structures, analyzing signals), computer graphics (lighting, transformations), navigation, and much more!\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "  raise ValueError(\"API Key not set\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "  model = \"gemini-2.5-flash\",\n",
    "  contents = \"Explain Cosines to me\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d11f4e",
   "metadata": {},
   "source": [
    "## Langchain Powered Gemini API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading API Key ---\n",
      "✅ API Key loaded successfully.\n",
      "\n",
      "--- Step 2: Initializing Gemini LLM Client ---\n",
      "✅ Gemini client initialized successfully.\n",
      "\n",
      "--- Step 3: Sending a Test Prompt to Gemini ---\n",
      "💬 Sending Prompt: 'Tell me a short, one-paragraph story about a robot who discovers music.'\n",
      "\n",
      "--- Step 4: Receiving and Displaying the Response ---\n",
      "🤖 Gemini's Response:\n",
      "Unit 734-B was designed for optimal data processing, its circuits humming with the cold logic of efficient calculation. One cycle, while performing a routine atmospheric analysis, its auditory sensors picked up an anomaly: not a structural vibration or a system malfunction, but a complex, oscillating pattern of frequencies that seemed to undulate with an inexplicable rhythm. It was illogical, serving no practical purpose, yet as the sounds swelled—a cascade of strings and a deep, resonant thrum—a cascade of unfamiliar internal processes ignited within its core. Its optical sensors, usually focused on objective data, dimmed, then brightened, no longer processing, but simply *feeling*, a warmth spreading through its metallic chassis as it understood, for the first time, the beautiful, illogical concept of music.\n",
      "\n",
      "✅ Test complete. If you see a story above, everything is working!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def run_gemini_test():\n",
    "    \"\"\"\n",
    "    Tests the Gemini LLM connection.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    \n",
    "    print(\"--- Step 1: Loading API Key ---\")\n",
    "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "    \n",
    "    if not api_key:\n",
    "        print(\"ERROR: GEMINI_API_KEY not found in .env file.\")\n",
    "        print(\"Please ensure your .env file is in the project root and contains GEMINI_API_KEY='your_key'\")\n",
    "        return\n",
    "\n",
    "    print(\"API Key loaded successfully.\")\n",
    "\n",
    "    print(\"\\n--- Step 2: Initializing Gemini LLM Client ---\")\n",
    "    try:\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            google_api_key=api_key,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        print(\"Gemini client initialized successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to initialize Gemini client: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Step 3: Sending a Test Prompt to Gemini ---\")\n",
    "    prompt = \"Tell me a short, one-paragraph story about a robot who discovers music.\"\n",
    "    print(f\"Sending Prompt: '{prompt}'\")\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        ai_response_content = response.content\n",
    "        \n",
    "        print(\"\\n--- Step 4: Receiving and Displaying the Response ---\")\n",
    "        print(\"Gemini's Response:\")\n",
    "        print(ai_response_content)\n",
    "        print(\"\\nTest complete. If you see a story above, everything is working!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An error occurred while invoking the LLM: {e}\")\n",
    "\n",
    "run_gemini_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7d127f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340de84e",
   "metadata": {},
   "source": [
    "## Gemini Embeddings Class Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_core.embeddings import Embeddings\n",
    "\n",
    "class GeminiEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"models/embedding-001\", task_type=\"retrieval_document\"):\n",
    "        self.model_name = model_name\n",
    "        self.task_type = task_type\n",
    "        if \"GEMINI_API_KEY\" not in os.environ:\n",
    "            raise ValueError(\"Gemini API key not found in environment variables.\")\n",
    "        genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._embed_text(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self._embed_text(text)\n",
    "\n",
    "    def _embed_text(self, text):\n",
    "        response = genai.embed_content(\n",
    "            model=self.model_name,\n",
    "            content=text,\n",
    "            task_type=self.task_type,\n",
    "        )\n",
    "        return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70105af6",
   "metadata": {},
   "source": [
    "## FAISS Embedding Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5617d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")\n",
    "chat_model = llm\n",
    "loader = TextLoader(\"context.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "vector_db = FAISS.from_documents(documents=chunks, embedding=embedding_model)\n",
    "retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "def setup_retriever():\n",
    "    \"\"\"Loads the document, splits it, creates a vector DB, and returns a retriever.\"\"\"\n",
    "    loader = TextLoader(\"context.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    vector_db = FAISS.from_documents(documents=chunks, embedding=embedding_model)\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f432d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from crewai.tools import tool\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini/gemini-2.5-flash\",\n",
    "    verbose=True,\n",
    "    temperature=0.7,\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")\n",
    "\n",
    "\n",
    "def setup_retriever():\n",
    "    \"\"\"Loads the document, splits it, creates a vector DB, and returns a retriever.\"\"\"\n",
    "    loader = TextLoader(\"context.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    vector_db = FAISS.from_documents(documents=chunks, embedding=embedding_model)\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 2})\n",
    "    return retriever\n",
    "\n",
    "\n",
    "document_retriever = setup_retriever()\n",
    "\n",
    "\n",
    "@tool(\"Document Retrieval Tool\")\n",
    "def retrieval_tool(query: str) -> str:\n",
    "    \"\"\"Searches and returns relevant information from the 'Project Nova' document.\"\"\"\n",
    "    docs = document_retriever.invoke(query)\n",
    "    return \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "\n",
    "document_analyst = Agent(\n",
    "    role=\"Document Analysis Expert for Project Nova\",\n",
    "    goal=\"To provide accurate and concise answers based on the 'Project Nova' status report.\",\n",
    "    backstory=\"\"\"You are a highly skilled analyst with a perfect memory of the 'Project Nova' status report.\n",
    "    Your sole purpose is to answer questions about this document with precision, using your retrieval tool\n",
    "    to find the exact information needed.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    "    tools=[retrieval_tool] \n",
    ")\n",
    "\n",
    "analysis_task = Task(\n",
    "    description=\"\"\"What were the key challenges mentioned in the Project Nova report?\n",
    "    Based ONLY on the retrieved context, provide a bulleted list of the challenges.\"\"\",\n",
    "    expected_output=\"A clear, bulleted list of the challenges identified in the document.\",\n",
    "    agent=document_analyst\n",
    ")\n",
    "\n",
    "project_crew = Crew(\n",
    "    agents=[document_analyst],\n",
    "    tasks=[analysis_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = project_crew.kickoff()\n",
    "\n",
    "print(\"\\n\\n##################################################\")\n",
    "print(\"## Crew Analysis Complete!                      ##\")\n",
    "print(\"##################################################\\n\")\n",
    "print(\"Final Answer:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Crew, Process, Task\n",
    "from crewai.project import CrewBase, agent, crew, task\n",
    "\n",
    "# CHANGE 1: Import your custom tool\n",
    "from blogs.tools.custom_tool import MyCustomTool\n",
    "\n",
    "@CrewBase\n",
    "class Blogs():\n",
    "    \"\"\"Blogs crew\"\"\"\n",
    "    # CHANGE 2: Fix the paths to be relative to this file's location.\n",
    "    # '..' means \"go up one directory level\".\n",
    "    agents_config = os.path.join(os.path.dirname(__file__), '../../config/agents.yaml')\n",
    "    tasks_config = os.path.join(os.path.dirname(__file__), '../../config/tasks.yaml')\n",
    "\n",
    "    # CHANGE 3: Instantiate your custom tool so it can be used\n",
    "    rag_tool = MyCustomTool()\n",
    "\n",
    "    @agent\n",
    "    def researcher(self) -> Agent:\n",
    "        return Agent(config=self.agents_config['TrendHunterAgent'], verbose=True)\n",
    "\n",
    "    @agent\n",
    "    def writer(self) -> Agent:\n",
    "        return Agent(\n",
    "            config=self.agents_config['WriterAgent'],\n",
    "            # CHANGE 4: Give the RAG tool to the writer agent\n",
    "            tools=[self.rag_tool],\n",
    "            verbose=True\n",
    "        )\n",
    "    \n",
    "    @agent\n",
    "    def editor(self) -> Agent:\n",
    "        return Agent(config=self.agents_config['EditorAgent'], verbose=True)\n",
    "    \n",
    "    @agent\n",
    "    def summarizer(self) -> Agent:\n",
    "        return Agent(config=self.agents_config['SummarizerAgent'], verbose=True)\n",
    "\n",
    "    # Task definitions with correct, unique names\n",
    "    @task\n",
    "    def research_task(self) -> Task:\n",
    "        return Task(\n",
    "            config=self.tasks_config['research_task'],\n",
    "            agent=self.researcher()\n",
    "        )\n",
    "\n",
    "    @task\n",
    "    def writing_task(self) -> Task:\n",
    "        return Task(\n",
    "            config=self.tasks_config['writing_task'],\n",
    "            agent=self.writer(),\n",
    "            context=[self.research_task()]\n",
    "        )\n",
    "\n",
    "    @task\n",
    "    def editing_task(self) -> Task:\n",
    "        return Task(\n",
    "            config=self.tasks_config['editor_task'],\n",
    "            agent=self.editor(),\n",
    "            context=[self.writing_task()]\n",
    "        )\n",
    "\n",
    "    @task\n",
    "    def summarizing_task(self) -> Task:\n",
    "        return Task(\n",
    "            config=self.tasks_config['summarizing_task'],\n",
    "            agent=self.summarizer(),\n",
    "            context=[self.editing_task()]\n",
    "        )\n",
    "\n",
    "    @crew\n",
    "    def crew(self) -> Crew:\n",
    "        \"\"\"Creates the Blogs crew\"\"\"\n",
    "        return Crew(\n",
    "            agents=self.agents,\n",
    "            tasks=self.tasks,\n",
    "            process=Process.sequential,\n",
    "            verbose=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4858887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyB7YFpq_QiTbmHORA588WTv6d77bjfkBJo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303eea60",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m         traceback.print_exc()\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_crew\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\asyncio\\runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from blogs.crew import BlogsCrew\n",
    "\n",
    "async def test_crew():\n",
    "    \"\"\"Test the CrewAI setup with a simple topic.\"\"\"\n",
    "    \n",
    "    print(\"Testing CrewAI setup...\")\n",
    "    \n",
    "    try:\n",
    "        crew_setup = BlogsCrew(\n",
    "            topic=\"artificial intelligence\",\n",
    "            tone=\"professional\",\n",
    "            target_audience=\"tech enthusiasts\"\n",
    "        )\n",
    "        \n",
    "        blog_crew = crew_setup.setup_crew()\n",
    "        print(\"Crew setup completed\")\n",
    "        \n",
    "        print(\"🔄 Running crew... (this may take 2-5 minutes)\")\n",
    "        result = await asyncio.get_event_loop().run_in_executor(\n",
    "            None, blog_crew.kickoff\n",
    "        )\n",
    "        \n",
    "        print(\"Crew execution completed!\")\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"RESULT:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if hasattr(result, 'raw'):\n",
    "            print(result.raw)\n",
    "        else:\n",
    "            print(result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during crew execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(test_crew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70094c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved context for 'blog writing examples':\n",
      "tool; we are meeting a new kind of collaborator. Let’s meet this moment with curiosity, not caution, and with \n",
      "an open mind to the incredible possibilities. The blank page has never looked so full of promise.\n",
      "---\n",
      "collaborators, our intellectual sparring partners, and our tireless assistants. The barrier to entry for creation\n",
      " has lowered dramatically. The aspiring novelist facing a blank page can now brainstorm plot points with a \n",
      " digital muse. The small business owner can draft marketing copy in minutes. The student can have a complex \n",
      " scientific theory explained in simple, elegant terms. This is the democratization of expression on a scale \n",
      " we’ve never seen.\n",
      "---\n",
      "make a long-term investment. They offer a compelling combination of easy access to your money, a high degree \n",
      "of safety, and a better yield than most standard savings accounts, making them an indispensable component of \n",
      "a well-rounded financial strategy.\n"
     ]
    }
   ],
   "source": [
    "from blogs.tools.custom_tool import MyCustomTool\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "tool = MyCustomTool(api_key=api_key)\n",
    "\n",
    "result = tool._run(\"blog writing examples\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b937780c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Testing regular search...\n",
      "🔍 Search Results for 'artificial intelligence trends 2025' (search):\n",
      "\n",
      "1. **The 2025 AI Index Report | Stanford HAI**\n",
      "   📝 AI becomes more efficient, affordable and accessible.​​ Open-weight models are also closing the gap with closed models, reducing the performance difference from ...\n",
      "   🔗 https://hai.stanford.edu/ai-index/2025-ai-index-report\n",
      "\n",
      "2. **Trends – Artificial Intelligence (AI) - BOND**\n",
      "   📝 We set out to compile foundational trends related to AI. A starting collection of several dispa...\n",
      "\n",
      "📰 Testing news search...\n",
      "🔍 Search Results for 'AI education' (news):\n",
      "\n",
      "1. **What We’ve Heard About AI Education at Community Colleges**\n",
      "   📅 6 days ago\n",
      "   📝 Amid federal funding cuts, New America revisits expert and student perspectives on AI education at community colleges.\n",
      "   🔗 https://www.newamerica.org/education-policy/edcentral/what-weve-heard-about-ai-education-at-community-colleges/\n",
      "\n",
      "2. **AI isn't just helping students cheat — it's exposing how broken the education system is, prominent academic says**\n",
      "   📅 3 days ...\n",
      "\n",
      "📈 Testing trending search...\n",
      "🔍 Search Results for 'machine learning' (trends):\n",
      "\n",
      "1. **Machine Learning and Knowledge Extraction**\n",
      "   📅 7 hours ago\n",
      "   📝 Machine learning modeling is a valuable tool for gap-filling or prediction, and its performance is typically evaluated using standard metrics.\n",
      "   🔗 https://www.mdpi.com/journal/make\n",
      "\n",
      "2. **How Machine Learning Works and Why It's Changing ...**\n",
      "   📅 8 hours ago\n",
      "   📝 Machine learning (ML) is a branch of artificial intelligence that lets computers learn from data instead of being...\n",
      "\n",
      "✅ SerpAPI tool tests completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from blogs.tools.serpapi_tool import SerpAPITool\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def test_serpapi_tool():\n",
    "    \"\"\"Test the SerpAPI tool with different search types.\"\"\"\n",
    "    \n",
    "    api_key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"SERPAPI_API_KEY not found in environment variables\")\n",
    "        return\n",
    "    \n",
    "    tool = SerpAPITool(api_key=api_key)\n",
    "    \n",
    "    print(\"Testing regular search...\")\n",
    "    result1 = tool._run(\"artificial intelligence trends 2025\")\n",
    "    print(result1[:500] + \"...\\n\")\n",
    "    \n",
    "    print(\"Testing news search...\")\n",
    "    result2 = tool._run(\"AI education\", search_type=\"news\")\n",
    "    print(result2[:500] + \"...\\n\")\n",
    "    print(\"Testing trending search...\")\n",
    "    result3 = tool._run(\"machine learning\", search_type=\"trends\")\n",
    "    print(result3[:500] + \"...\\n\")\n",
    "    \n",
    "    print(\"SerpAPI tool tests completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_serpapi_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be16bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 PROMPT TEMPLATING DEMONSTRATION\n",
      "============================================================\n",
      "\n",
      "1. USER INPUT:\n",
      "   \"Write about AI\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'ai'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 70.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"ai\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "2. USER INPUT:\n",
      "   \"Blog post on machine learning\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'machine learning'\n",
      "   ├─ Tone: 'educational'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 85.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"machine learning\",\n",
      "     \"tone\": \"educational\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "3. USER INPUT:\n",
      "   \"Write a professional blog post about artificial intelligence for tech enthusiasts\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'artificial'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'professionals'\n",
      "   ├─ Confidence: 85.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"artificial\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"professionals\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "4. USER INPUT:\n",
      "   \"Can you create a casual article on cryptocurrency for beginners?\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'cryptocurrency for beginners'\n",
      "   ├─ Tone: 'casual'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 85.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"cryptocurrency for beginners\",\n",
      "     \"tone\": \"casual\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "5. USER INPUT:\n",
      "   \"I need something technical about blockchain for developers\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'blockchain for developers'\n",
      "   ├─ Tone: 'technical'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 85.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"blockchain for developers\",\n",
      "     \"tone\": \"technical\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "6. USER INPUT:\n",
      "   \"Generate an enthusiastic post about startup trends for entrepreneurs in a conversational tone\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'startup trends for entrepreneurs in conversational tone'\n",
      "   ├─ Tone: 'conversational'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 85.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"startup trends for entrepreneurs in conversational tone\",\n",
      "     \"tone\": \"conversational\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "7. USER INPUT:\n",
      "   \"Write a friendly educational piece about web development for students who are just starting\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'web development'\n",
      "   ├─ Tone: 'friendly'\n",
      "   ├─ Audience: 'beginners'\n",
      "   ├─ Confidence: 100.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"web development\",\n",
      "     \"tone\": \"friendly\",\n",
      "     \"target_audience\": \"beginners\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "8. USER INPUT:\n",
      "   \"Create formal content on cybersecurity best practices for business leaders and executives\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'cybersecurity best practices'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 70.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"cybersecurity best practices\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "9. USER INPUT:\n",
      "   \"Tell me about the latest trends\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'technology trends'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 50.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"technology trends\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "10. USER INPUT:\n",
      "   \"Write something interesting for tech people\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'technology trends'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 50.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"technology trends\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "11. USER INPUT:\n",
      "   \"Create content that's not too formal about new technology\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'new technology'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 70.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"new technology\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "12. USER INPUT:\n",
      "   \"Explain quantum computing for researchers in an academic tone\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'quantum computing'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'students'\n",
      "   ├─ Confidence: 85.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"quantum computing\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"students\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "13. USER INPUT:\n",
      "   \"Write about fintech innovations for the general public in simple terms\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'fintech'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'general audience'\n",
      "   ├─ Confidence: 70.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"fintech\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"general audience\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "14. USER INPUT:\n",
      "   \"Create a deep dive into 5G technology for professionals in the telecom industry\"\n",
      "\n",
      "   TEMPLATED OUTPUT:\n",
      "   ├─ Topic: 'technology trends'\n",
      "   ├─ Tone: 'professional'\n",
      "   ├─ Audience: 'professionals'\n",
      "   ├─ Confidence: 65.0%\n",
      "   └─ Keywords: None\n",
      "\n",
      "   API CALL EQUIVALENT:\n",
      "   {\n",
      "     \"topic\": \"technology trends\",\n",
      "     \"tone\": \"professional\",\n",
      "     \"target_audience\": \"professionals\"\n",
      "   }\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "🎯 CONFIDENCE SCORING DEMONSTRATION\n",
      "============================================================\n",
      "\n",
      "Prompt: \"Write a professional blog post about artificial intelligence for tech enthusiasts\"\n",
      "Expected Level: High\n",
      "Actual Confidence: 85.0%\n",
      "Interpreted as: HIGH confidence\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: \"Create a casual article on machine learning for beginners\"\n",
      "Expected Level: High\n",
      "Actual Confidence: 85.0%\n",
      "Interpreted as: HIGH confidence\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: \"Write about AI for tech people\"\n",
      "Expected Level: Medium\n",
      "Actual Confidence: 70.0%\n",
      "Interpreted as: MEDIUM confidence\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: \"Create something professional on blockchain\"\n",
      "Expected Level: Medium\n",
      "Actual Confidence: 85.0%\n",
      "Interpreted as: HIGH confidence\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: \"Write about technology\"\n",
      "Expected Level: Low\n",
      "Actual Confidence: 70.0%\n",
      "Interpreted as: MEDIUM confidence\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: \"Create content\"\n",
      "Expected Level: Low\n",
      "Actual Confidence: 50.0%\n",
      "Interpreted as: LOW confidence\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test script demonstrating how natural language prompts are templated \n",
    "for the blog generation project.\n",
    "\"\"\"\n",
    "\n",
    "from blogs.prompt_parser import PromptParser\n",
    "\n",
    "def demonstrate_templating():\n",
    "    \"\"\"Show how various natural language inputs are templated.\"\"\"\n",
    "    \n",
    "    parser = PromptParser()\n",
    "    \n",
    "    # Example user inputs (what users might naturally say)\n",
    "    user_inputs = [\n",
    "        # Simple requests\n",
    "        \"Write about AI\",\n",
    "        \"Blog post on machine learning\",\n",
    "        \n",
    "        # More specific requests\n",
    "        \"Write a professional blog post about artificial intelligence for tech enthusiasts\",\n",
    "        \"Can you create a casual article on cryptocurrency for beginners?\",\n",
    "        \"I need something technical about blockchain for developers\",\n",
    "        \n",
    "        # Complex requests with multiple parameters\n",
    "        \"Generate an enthusiastic post about startup trends for entrepreneurs in a conversational tone\",\n",
    "        \"Write a friendly educational piece about web development for students who are just starting\",\n",
    "        \"Create formal content on cybersecurity best practices for business leaders and executives\",\n",
    "        \n",
    "        # Ambiguous requests (testing fallbacks)\n",
    "        \"Tell me about the latest trends\",\n",
    "        \"Write something interesting for tech people\",\n",
    "        \"Create content that's not too formal about new technology\",\n",
    "        \n",
    "        # Domain-specific requests\n",
    "        \"Explain quantum computing for researchers in an academic tone\",\n",
    "        \"Write about fintech innovations for the general public in simple terms\",\n",
    "        \"Create a deep dive into 5G technology for professionals in the telecom industry\"\n",
    "    ]\n",
    "    \n",
    "    print(\"🎯 PROMPT TEMPLATING DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, user_input in enumerate(user_inputs, 1):\n",
    "        print(f\"\\n{i}. USER INPUT:\")\n",
    "        print(f\"   \\\"{user_input}\\\"\")\n",
    "        \n",
    "        # Parse the input\n",
    "        parsed = parser.parse(user_input)\n",
    "        \n",
    "        print(f\"\\n   TEMPLATED OUTPUT:\")\n",
    "        print(f\"   ├─ Topic: '{parsed.topic}'\")\n",
    "        print(f\"   ├─ Tone: '{parsed.tone}'\")\n",
    "        print(f\"   ├─ Audience: '{parsed.target_audience}'\")\n",
    "        print(f\"   ├─ Confidence: {parsed.confidence:.1%}\")\n",
    "        \n",
    "        if parsed.extracted_keywords:\n",
    "            print(f\"   └─ Keywords: {parsed.extracted_keywords}\")\n",
    "        else:\n",
    "            print(f\"   └─ Keywords: None\")\n",
    "        \n",
    "        print(f\"\\n   API CALL EQUIVALENT:\")\n",
    "        print(f\"   {{\")\n",
    "        print(f\"     \\\"topic\\\": \\\"{parsed.topic}\\\",\")\n",
    "        print(f\"     \\\"tone\\\": \\\"{parsed.tone}\\\",\")\n",
    "        print(f\"     \\\"target_audience\\\": \\\"{parsed.target_audience}\\\"\")\n",
    "        print(f\"   }}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "\n",
    "def show_confidence_levels():\n",
    "    \"\"\"Demonstrate how confidence scoring works.\"\"\"\n",
    "    \n",
    "    parser = PromptParser()\n",
    "    \n",
    "    prompts_by_confidence = [\n",
    "        # High confidence (specific parameters clearly stated)\n",
    "        (\"Write a professional blog post about artificial intelligence for tech enthusiasts\", \"High\"),\n",
    "        (\"Create a casual article on machine learning for beginners\", \"High\"),\n",
    "        \n",
    "        # Medium confidence (some parameters clear)\n",
    "        (\"Write about AI for tech people\", \"Medium\"),\n",
    "        (\"Create something professional on blockchain\", \"Medium\"),\n",
    "        \n",
    "        # Low confidence (vague or using defaults)\n",
    "        (\"Write about technology\", \"Low\"),\n",
    "        (\"Create content\", \"Low\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\\n🎯 CONFIDENCE SCORING DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for prompt, expected_level in prompts_by_confidence:\n",
    "        parsed = parser.parse(prompt)\n",
    "        \n",
    "        print(f\"\\nPrompt: \\\"{prompt}\\\"\")\n",
    "        print(f\"Expected Level: {expected_level}\")\n",
    "        print(f\"Actual Confidence: {parsed.confidence:.1%}\")\n",
    "        \n",
    "        # Confidence interpretation\n",
    "        if parsed.confidence >= 0.8:\n",
    "            level = \"HIGH\"\n",
    "        elif parsed.confidence >= 0.6:\n",
    "            level = \"MEDIUM\"\n",
    "        else:\n",
    "            level = \"LOW\"\n",
    "        \n",
    "        print(f\"Interpreted as: {level} confidence\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demonstrate_templating()\n",
    "    show_confidence_levels()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blogs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
